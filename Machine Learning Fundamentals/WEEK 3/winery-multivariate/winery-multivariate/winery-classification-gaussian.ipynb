{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Winery classification with the multivariate Gaussian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we return to winery classification, using the full set of 13 features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load in the data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, we start by loading in the Wine data set. Make sure the file `wine.data.txt` is in the same directory as this notebook.\n",
    "\n",
    "Recall that there are 178 data points, each with 13 features and a label (1,2,3). As before, we will divide this into a training set of 130 points and a test set of 48 points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard includes\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Useful module for dealing with the Gaussian density\n",
    "from scipy.stats import norm, multivariate_normal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data set.\n",
    "data = np.loadtxt('wine.data.txt', delimiter=',')\n",
    "# Names of features\n",
    "featurenames = ['Alcohol', 'Malic acid', 'Ash', 'Alcalinity of ash','Magnesium', 'Total phenols', \n",
    "                'Flavanoids', 'Nonflavanoid phenols', 'Proanthocyanins', 'Color intensity', 'Hue', \n",
    "                'OD280/OD315 of diluted wines', 'Proline']\n",
    "# Split 178 instances into training set (trainx, trainy) of size 130 and test set (testx, testy) of size 48\n",
    "np.random.seed(0)\n",
    "perm = np.random.permutation(178)\n",
    "trainx = data[perm[0:130],1:14]\n",
    "trainy = data[perm[0:130],0]\n",
    "testx = data[perm[130:178], 1:14]\n",
    "testy = data[perm[130:178],0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Fit a Gaussian generative model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now define a function that fits a Gaussian generative model to the data.\n",
    "For each class (`j=1,2,3`), we have:\n",
    "* `pi[j]`: the class weight\n",
    "* `mu[j,:]`: the mean, a 13-dimensional vector\n",
    "* `sigma[j,:,:]`: the 13x13 covariance matrix\n",
    "\n",
    "This means that `pi` is a 4x1 array (Python arrays are indexed starting at zero, and we aren't using `j=0`), `mu` is a 4x13 array and `sigma` is a 4x13x13 array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_generative_model(x,y):\n",
    "    k = 3  # labels 1,2,...,k\n",
    "    d = (x.shape)[1]  # number of features\n",
    "    mu = np.zeros((k+1,d))\n",
    "    sigma = np.zeros((k+1,d,d))\n",
    "    pi = np.zeros(k+1)\n",
    "    for label in range(1,k+1):\n",
    "        indices = (y == label)\n",
    "        mu[label] = np.mean(x[indices,:], axis=0)\n",
    "        sigma[label] = np.cov(x[indices,:], rowvar=0, bias=1)\n",
    "        pi[label] = float(sum(indices))/float(len(y))\n",
    "    return mu, sigma, pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a Gaussian generative model to the training data\n",
    "mu, sigma, pi = fit_generative_model(trainx,trainy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Use the model to make predictions on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"magenta\">**For you to do**</font>: Define a general purpose testing routine that takes as input:\n",
    "* the arrays `pi`, `mu`, `sigma` defining the generative model, as above\n",
    "* the test set (points `tx` and labels `ty`)\n",
    "* a list of features `features` (chosen from 0-12)\n",
    "\n",
    "It should return the number of mistakes made by the generative model on the test data, *when restricted to the specified features*. For instance, using the just three features 2 (`'Ash'`), 4 (`'Magnesium'`) and 6 (`'Flavanoids'`) results in 7 mistakes (out of 48 test points), so \n",
    "\n",
    "        `test_model(mu, sigma, pi, [2,4,6], testx, testy)` \n",
    "\n",
    "should print 7/48.\n",
    "\n",
    "**Hint:** The way you restrict attention to a subset of features is by choosing the corresponding coordinates of the full 13-dimensional mean and the appropriate submatrix of the full 13x13 covariance matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "LinAlgError",
     "evalue": "When `allow_singular is False`, the input matrix must be symmetric positive definite.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 38\u001b[0m\n\u001b[0;32m     35\u001b[0m features \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m6\u001b[39m]\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Calculate mistakes made by the generative model on the test data using the specified features\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m num_mistakes \u001b[38;5;241m=\u001b[39m \u001b[43mtest_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtestx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtesty\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Print the number of mistakes\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m mistakes\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(num_mistakes, \u001b[38;5;28mlen\u001b[39m(testy)))\n",
      "Cell \u001b[1;32mIn[12], line 21\u001b[0m, in \u001b[0;36mtest_model\u001b[1;34m(mu, sigma, pi, features, testx, testy)\u001b[0m\n\u001b[0;32m     19\u001b[0m score \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(k)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(k):\n\u001b[1;32m---> 21\u001b[0m     rv \u001b[38;5;241m=\u001b[39m \u001b[43mmultivariate_normal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmean\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmu_selected\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcov\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msigma_selected\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m     score[label] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(pi[label]) \u001b[38;5;241m+\u001b[39m rv\u001b[38;5;241m.\u001b[39mlogpdf(x)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Assign label based on maximum log-likelihood score\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\HP\\Documents\\python projects\\.venv\\Lib\\site-packages\\scipy\\stats\\_multivariate.py:397\u001b[0m, in \u001b[0;36mmultivariate_normal_gen.__call__\u001b[1;34m(self, mean, cov, allow_singular, seed)\u001b[0m\n\u001b[0;32m    392\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, mean\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, cov\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, allow_singular\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    393\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create a frozen multivariate normal distribution.\u001b[39;00m\n\u001b[0;32m    394\u001b[0m \n\u001b[0;32m    395\u001b[0m \u001b[38;5;124;03m    See `multivariate_normal_frozen` for more information.\u001b[39;00m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmultivariate_normal_frozen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcov\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    398\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mallow_singular\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_singular\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    399\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\HP\\Documents\\python projects\\.venv\\Lib\\site-packages\\scipy\\stats\\_multivariate.py:903\u001b[0m, in \u001b[0;36mmultivariate_normal_frozen.__init__\u001b[1;34m(self, mean, cov, allow_singular, seed, maxpts, abseps, releps)\u001b[0m\n\u001b[0;32m    860\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Create a frozen multivariate normal distribution.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m \n\u001b[0;32m    862\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    899\u001b[0m \n\u001b[0;32m    900\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m \u001b[38;5;66;03m# numpy/numpydoc#87  # noqa: E501\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dist \u001b[38;5;241m=\u001b[39m multivariate_normal_gen(seed)\n\u001b[0;32m    902\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdim, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmean, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcov_object \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 903\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcov\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_singular\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    904\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mallow_singular \u001b[38;5;241m=\u001b[39m allow_singular \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcov_object\u001b[38;5;241m.\u001b[39m_allow_singular\n\u001b[0;32m    905\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m maxpts:\n",
      "File \u001b[1;32mc:\\Users\\HP\\Documents\\python projects\\.venv\\Lib\\site-packages\\scipy\\stats\\_multivariate.py:421\u001b[0m, in \u001b[0;36mmultivariate_normal_gen._process_parameters\u001b[1;34m(self, mean, cov, allow_singular)\u001b[0m\n\u001b[0;32m    414\u001b[0m dim, mean, cov \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_parameters_psd(\u001b[38;5;28;01mNone\u001b[39;00m, mean, cov)\n\u001b[0;32m    415\u001b[0m \u001b[38;5;66;03m# After input validation, some methods then processed the arrays\u001b[39;00m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;66;03m# with a `_PSD` object and used that to perform computation.\u001b[39;00m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;66;03m# To avoid branching statements in each method depending on whether\u001b[39;00m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;66;03m# `cov` is an array or `Covariance` object, we always process the\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;66;03m# array with `_PSD`, and then use wrapper that satisfies the\u001b[39;00m\n\u001b[0;32m    420\u001b[0m \u001b[38;5;66;03m# `Covariance` interface, `CovViaPSD`.\u001b[39;00m\n\u001b[1;32m--> 421\u001b[0m psd \u001b[38;5;241m=\u001b[39m \u001b[43m_PSD\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcov\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_singular\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_singular\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    422\u001b[0m cov_object \u001b[38;5;241m=\u001b[39m _covariance\u001b[38;5;241m.\u001b[39mCovViaPSD(psd)\n\u001b[0;32m    423\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dim, mean, cov_object\n",
      "File \u001b[1;32mc:\\Users\\HP\\Documents\\python projects\\.venv\\Lib\\site-packages\\scipy\\stats\\_multivariate.py:174\u001b[0m, in \u001b[0;36m_PSD.__init__\u001b[1;34m(self, M, cond, rcond, lower, check_finite, allow_singular)\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(d) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(s) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_singular:\n\u001b[0;32m    172\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen `allow_singular is False`, the input matrix must be \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    173\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msymmetric positive definite.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 174\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mLinAlgError(msg)\n\u001b[0;32m    175\u001b[0m s_pinv \u001b[38;5;241m=\u001b[39m _pinv_1d(s, eps)\n\u001b[0;32m    176\u001b[0m U \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmultiply(u, np\u001b[38;5;241m.\u001b[39msqrt(s_pinv))\n",
      "\u001b[1;31mLinAlgError\u001b[0m: When `allow_singular is False`, the input matrix must be symmetric positive definite."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "def test_model(mu, sigma, pi, features, testx, testy):\n",
    "    mistakes = 0\n",
    "    k = len(pi)  # Number of classes\n",
    "    \n",
    "    # Select specified features from the mean vector for each class\n",
    "    mu_selected = mu[:, features]\n",
    "    \n",
    "    # Select submatrices from the covariance matrix for each class\n",
    "    sigma_selected = sigma[:, features][:, :, features]\n",
    "    \n",
    "    # Compute log-likelihood scores for each test point and each class\n",
    "    for i in range(len(testy)):\n",
    "        x = testx[i, features]  # Select specified features for the current test point\n",
    "        \n",
    "        # Compute log-likelihood scores for each class\n",
    "        score = np.zeros(k)\n",
    "        for label in range(k):\n",
    "            rv = multivariate_normal(mean=mu_selected[label], cov=sigma_selected[label])\n",
    "            score[label] = np.log(pi[label]) + rv.logpdf(x)\n",
    "        \n",
    "        # Assign label based on maximum log-likelihood score\n",
    "        predicted_label = np.argmax(score)\n",
    "        \n",
    "        # Check if predicted label is incorrect\n",
    "        if predicted_label != testy[i]:\n",
    "            mistakes += 1\n",
    "    \n",
    "    return mistakes\n",
    "\n",
    "# Example usage:\n",
    "# Specify features to use\n",
    "features = [2, 4, 6]\n",
    "\n",
    "# Calculate mistakes made by the generative model on the test data using the specified features\n",
    "num_mistakes = test_model(mu, sigma, pi, features, testx, testy)\n",
    "\n",
    "# Print the number of mistakes\n",
    "print(\"{}/{} mistakes\".format(num_mistakes, len(testy)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"magenta\">Fast exercises</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note down the answers to these questions. You will need to enter them as part of this week's assignment.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 1. How many errors are made on the test set when using the single feature 'Ash'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "LinAlgError",
     "evalue": "When `allow_singular is False`, the input matrix must be symmetric positive definite.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtest_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtestx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtesty\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[12], line 21\u001b[0m, in \u001b[0;36mtest_model\u001b[1;34m(mu, sigma, pi, features, testx, testy)\u001b[0m\n\u001b[0;32m     19\u001b[0m score \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(k)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(k):\n\u001b[1;32m---> 21\u001b[0m     rv \u001b[38;5;241m=\u001b[39m \u001b[43mmultivariate_normal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmean\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmu_selected\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcov\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msigma_selected\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m     score[label] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(pi[label]) \u001b[38;5;241m+\u001b[39m rv\u001b[38;5;241m.\u001b[39mlogpdf(x)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Assign label based on maximum log-likelihood score\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\HP\\Documents\\python projects\\.venv\\Lib\\site-packages\\scipy\\stats\\_multivariate.py:397\u001b[0m, in \u001b[0;36mmultivariate_normal_gen.__call__\u001b[1;34m(self, mean, cov, allow_singular, seed)\u001b[0m\n\u001b[0;32m    392\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, mean\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, cov\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, allow_singular\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    393\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create a frozen multivariate normal distribution.\u001b[39;00m\n\u001b[0;32m    394\u001b[0m \n\u001b[0;32m    395\u001b[0m \u001b[38;5;124;03m    See `multivariate_normal_frozen` for more information.\u001b[39;00m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmultivariate_normal_frozen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcov\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    398\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mallow_singular\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_singular\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    399\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\HP\\Documents\\python projects\\.venv\\Lib\\site-packages\\scipy\\stats\\_multivariate.py:903\u001b[0m, in \u001b[0;36mmultivariate_normal_frozen.__init__\u001b[1;34m(self, mean, cov, allow_singular, seed, maxpts, abseps, releps)\u001b[0m\n\u001b[0;32m    860\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Create a frozen multivariate normal distribution.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m \n\u001b[0;32m    862\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    899\u001b[0m \n\u001b[0;32m    900\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m \u001b[38;5;66;03m# numpy/numpydoc#87  # noqa: E501\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dist \u001b[38;5;241m=\u001b[39m multivariate_normal_gen(seed)\n\u001b[0;32m    902\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdim, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmean, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcov_object \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 903\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcov\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_singular\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    904\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mallow_singular \u001b[38;5;241m=\u001b[39m allow_singular \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcov_object\u001b[38;5;241m.\u001b[39m_allow_singular\n\u001b[0;32m    905\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m maxpts:\n",
      "File \u001b[1;32mc:\\Users\\HP\\Documents\\python projects\\.venv\\Lib\\site-packages\\scipy\\stats\\_multivariate.py:421\u001b[0m, in \u001b[0;36mmultivariate_normal_gen._process_parameters\u001b[1;34m(self, mean, cov, allow_singular)\u001b[0m\n\u001b[0;32m    414\u001b[0m dim, mean, cov \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_parameters_psd(\u001b[38;5;28;01mNone\u001b[39;00m, mean, cov)\n\u001b[0;32m    415\u001b[0m \u001b[38;5;66;03m# After input validation, some methods then processed the arrays\u001b[39;00m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;66;03m# with a `_PSD` object and used that to perform computation.\u001b[39;00m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;66;03m# To avoid branching statements in each method depending on whether\u001b[39;00m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;66;03m# `cov` is an array or `Covariance` object, we always process the\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;66;03m# array with `_PSD`, and then use wrapper that satisfies the\u001b[39;00m\n\u001b[0;32m    420\u001b[0m \u001b[38;5;66;03m# `Covariance` interface, `CovViaPSD`.\u001b[39;00m\n\u001b[1;32m--> 421\u001b[0m psd \u001b[38;5;241m=\u001b[39m \u001b[43m_PSD\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcov\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_singular\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_singular\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    422\u001b[0m cov_object \u001b[38;5;241m=\u001b[39m _covariance\u001b[38;5;241m.\u001b[39mCovViaPSD(psd)\n\u001b[0;32m    423\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dim, mean, cov_object\n",
      "File \u001b[1;32mc:\\Users\\HP\\Documents\\python projects\\.venv\\Lib\\site-packages\\scipy\\stats\\_multivariate.py:174\u001b[0m, in \u001b[0;36m_PSD.__init__\u001b[1;34m(self, M, cond, rcond, lower, check_finite, allow_singular)\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(d) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(s) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_singular:\n\u001b[0;32m    172\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen `allow_singular is False`, the input matrix must be \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    173\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msymmetric positive definite.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 174\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mLinAlgError(msg)\n\u001b[0;32m    175\u001b[0m s_pinv \u001b[38;5;241m=\u001b[39m _pinv_1d(s, eps)\n\u001b[0;32m    176\u001b[0m U \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmultiply(u, np\u001b[38;5;241m.\u001b[39msqrt(s_pinv))\n",
      "\u001b[1;31mLinAlgError\u001b[0m: When `allow_singular is False`, the input matrix must be symmetric positive definite."
     ]
    }
   ],
   "source": [
    "test_model(mu, sigma, pi, [2], testx, testy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 2. How many errors when using 'Alcohol' and 'Ash'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(mu, sigma, pi, [0,2], testx, testy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 3. How many errors when using 'Alcohol', 'Ash', and 'Flavanoids'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(mu, sigma, pi, [0,2,6], testx, testy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 4. How many errors when using all 13 features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(mu, sigma, pi, range(0,13), testx, testy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 5. In lecture, we got somewhat different answers to these questions. Why do you think that might be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
