{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian generative models for handwritten digit classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the 1-NN classifier yielded a 3.09% test error rate on the MNIST data set of handwritten digits. We will now see that a Gaussian generative model does almost as well, while being significantly faster and more compact."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Set up notebook and load in data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, we start by importing the required packages and data. For this notebook we will be using the *entire* `MNIST` dataset. The code below defines some helper functions that will load `MNIST` onto your computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "import matplotlib.pyplot as plt \n",
    "import gzip, os\n",
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "if sys.version_info[0] == 2:\n",
    "    from urllib import urlretrieve\n",
    "else:\n",
    "    from urllib.request import urlretrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that downloads a specified MNIST data file from Yann Le Cun's website\n",
    "def download(filename, source='http://yann.lecun.com/exdb/mnist/'):\n",
    "    print(\"Downloading %s\" % filename)\n",
    "    urlretrieve(source + filename, filename)\n",
    "\n",
    "# Invokes download() if necessary, then reads in images\n",
    "def load_mnist_images(filename):\n",
    "    if not os.path.exists(filename):\n",
    "        download(filename)\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        data = np.frombuffer(f.read(), np.uint8, offset=16)\n",
    "    data = data.reshape(-1,784)\n",
    "    return data\n",
    "\n",
    "def load_mnist_labels(filename):\n",
    "    if not os.path.exists(filename):\n",
    "        download(filename)\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        data = np.frombuffer(f.read(), np.uint8, offset=8)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now load in the training set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading train-images-idx3-ubyte.gz\n",
      "Downloading train-labels-idx1-ubyte.gz\n",
      "Downloading t10k-images-idx3-ubyte.gz\n",
      "Downloading t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "## Load the training set\n",
    "train_data = load_mnist_images('train-images-idx3-ubyte.gz')\n",
    "train_labels = load_mnist_labels('train-labels-idx1-ubyte.gz')\n",
    "\n",
    "## Load the testing set\n",
    "test_data = load_mnist_images('t10k-images-idx3-ubyte.gz')\n",
    "test_labels = load_mnist_labels('t10k-labels-idx1-ubyte.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function **displaychar** shows a single MNIST digit. To do this, it first has to reshape the 784-dimensional vector into a 28x28 image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def displaychar(image):\n",
    "    plt.imshow(np.reshape(image, (28,28)), cmap=plt.cm.gray)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displaychar(train_data[58])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training set consists of 60,000 images. Thus `train_data` should be a 60000x784 array while `train_labels` should be 60000x1. Let's check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (60000,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape, train_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Fit a Gaussian generative model to the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color=\"magenta\">For you to do:</font>** Define a function, **fit_generative_model**, that takes as input a training set (data `x` and labels `y`) and fits a Gaussian generative model to it. It should return the parameters of this generative model; for each label `j = 0,1,...,9`, we have:\n",
    "* `pi[j]`: the frequency of that label\n",
    "* `mu[j]`: the 784-dimensional mean vector\n",
    "* `sigma[j]`: the 784x784 covariance matrix\n",
    "\n",
    "This means that `pi` is 10x1, `mu` is 10x784, and `sigma` is 10x784x784.\n",
    "\n",
    "We have already seen how to fit a Gaussian generative model in the Winery example, but now there is an added ingredient. <font color=\"magenta\">The empirical covariances are very likely to be singular (or close to singular), which means that we won't be able to do calculations with them</font>. Thus it is important to **regularize** these matrices. The standard way of doing this is to add `cI` to them, where `c` is some constant and `I` is the 784-dimensional identity matrix. (To put it another way, we compute the empirical covariances and then increase their diagonal entries by some constant `c`.)\n",
    "\n",
    "This modification is guaranteed to yield covariance matrices that are non-singular, for any `c > 0`, no matter how small. But this doesn't mean that we should make `c` as small as possible. Indeed, `c` is now a parameter, and by setting it appropriately, we can improve the performance of the model. We will study **regularization** in greater detail over the coming weeks.\n",
    "\n",
    "Your routine needs to choose a good setting of `c`. Crucially, this needs to be done using the training set alone. So you might try setting aside part of the training set as a validation set, or using some kind of cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**To implement the fit_generative_model function, we'll follow these steps:**\n",
    "\n",
    "- Calculate the frequency of each label.\n",
    "- Compute the mean vector for each label.\n",
    "- Estimate the covariance matrix for each label while regularizing it.\n",
    "- Choose an appropriate regularization parameter c.\n",
    "- Return the parameters of the generative model: pi, mu, and sigma.\n",
    "\n",
    "Here's the implementation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function Signature:**\n",
    "```python\n",
    "def fit_generative_model(x, y, c=1e-2):\n",
    "```\n",
    "- `x`: Input features (numpy array).\n",
    "- `y`: Labels (numpy array).\n",
    "- `c`: Regularization parameter, default value is `1e-2` (can be adjusted as needed).\n",
    "\n",
    "**Initialization:**\n",
    "```python\n",
    "k = 10  # Number of labels 0, 1, ..., k-1\n",
    "d = x.shape[1]  # Number of features\n",
    "\n",
    "mu = np.zeros((k, d))\n",
    "sigma = np.zeros((k, d, d))\n",
    "pi = np.zeros(k)\n",
    "```\n",
    "- `k`: Number of unique labels.\n",
    "- `d`: Number of features.\n",
    "- `mu`: Array to store mean vectors for each label.\n",
    "- `sigma`: Array to store covariance matrices for each label.\n",
    "- `pi`: Array to store the frequency of each label.\n",
    "\n",
    "**Loop Over Labels:**\n",
    "```python\n",
    "for label in range(k):\n",
    "```\n",
    "This loop iterates over each label (0 to 9 in this case).\n",
    "\n",
    "**Subsetting Data:**\n",
    "```python\n",
    "indices = (y == label)\n",
    "x_label = x[indices]\n",
    "```\n",
    "- `indices`: Boolean array indicating where `y` equals the current label.\n",
    "- `x_label`: Subset of input features corresponding to the current label.\n",
    "\n",
    "**Estimating Parameters:**\n",
    "```python\n",
    "pi[label] = len(x_label) / len(x)\n",
    "mu[label] = np.mean(x_label, axis=0)\n",
    "empirical_cov = np.cov(x_label, rowvar=False, bias=True)\n",
    "```\n",
    "- `pi[label]`: Estimate the frequency of the current label by dividing the count of instances with this label by the total number of instances.\n",
    "- `mu[label]`: Compute the mean vector of features for the current label.\n",
    "- `empirical_cov`: Compute the empirical covariance matrix for the current label using `np.cov`.\n",
    "\n",
    "**Regularization:**\n",
    "```python\n",
    "sigma[label] = empirical_cov + c * np.eye(d)\n",
    "```\n",
    "- Regularize the empirical covariance matrix by adding `c * np.eye(d)`, where `np.eye(d)` creates a `d x d` identity matrix.\n",
    "\n",
    "**Return Parameters:**\n",
    "```python\n",
    "return mu, sigma, pi\n",
    "```\n",
    "Return the mean vectors (`mu`), covariance matrices (`sigma`), and label frequencies (`pi`) as the output of the function.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def fit_generative_model(x, y, c=1e-2):\n",
    "    k = 10  # Number of labels 0, 1, ..., k-1\n",
    "    d = x.shape[1]  # Number of features\n",
    "\n",
    "    mu = np.zeros((k, d))\n",
    "    sigma = np.zeros((k, d, d))\n",
    "    pi = np.zeros(k)\n",
    "\n",
    "    for label in range(k):\n",
    "        indices = (y == label)\n",
    "        x_label = x[indices]\n",
    "        pi[label] = len(x_label) / len(x)\n",
    "\n",
    "        mu[label] = np.mean(x_label, axis=0)\n",
    "\n",
    "        # Compute the empirical covariance matrix\n",
    "        empirical_cov = np.cov(x_label, rowvar=False, bias=True)\n",
    "\n",
    "        # Regularize the covariance matrix\n",
    "        sigma[label] = empirical_cov + c * np.eye(d)\n",
    "   # Halt and return parameters\n",
    "    return mu, sigma, pi\n",
    "\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, let's try out your function. In particular, we will use **displaychar** to visualize the means of the Gaussians for the first three digits. You can try the other digits on your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAAANI0lEQVR4nO3cXXfNZ9fG4blEiJfGS6JKlNLhpdX2+3+OtqiBlluERNGQCCJZz9659WyY1xjN7Zbj2HaOtays+PW/0TmZTqfTAoCqOvDffgMAfD5EAYAQBQBCFAAIUQAgRAGAEAUAQhQAiIOf+gcnk8m/+T4A+Jd9yv+r7EkBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAIiD/+03wP4xmUz2bPc5b0ZNp9M92YzYy/e2V3+n/cqTAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAEA4iPeFGTnQNjMz097Mzs62N3Nzc+1NVdWJEyfam9OnT+/J64xsDh4c+7V7//59e/P69ev25sWLF+3Nq1ev2puR91ZV9e7du/bm48eP7c1+PbznSQGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgHMT7TB04MNbrkWNrR44caW9GDsGdO3euvamqunz5cntz7dq1PXmds2fPtjejhwE3Njbam+Xl5fbm3r177c2dO3fam4cPH7Y3VVWrq6vtzZs3b9qbkSN6XwJPCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgDhIN4eGDluN3LYrmrsuN3i4mJ7c/Hixfbmxo0b7U1V1U8//bQnrzXyd1pYWGhvZmdn25uqsQNta2tr7c3S0lJ7M3Ig8fDhw+1NVdXu7m57s7293d5sbm62N9PptL353HhSACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAgH8Zomk0l7M3IQb/RY2KlTp9qbkUNwN2/ebG9++eWX9qaq6vr16+3NyFG3+fn59mbk+zBy0K1q7Eji119/3d6MHHXb2dlpb969e9feVI0dqtvY2GhvRt7fyNHCz40nBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQDCldSmkauYs7Oz7c1XX33V3lRVnT9/vr25evVqe/Pjjz/uyetU7d2lz9XV1fZm5GLn9vZ2e1M19j0aufw6cqF35NLuP//8095UVT1//ry9efr0aXvz6tWr9saVVAC+KKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhIN4TQcO9Ds6NzfX3pw5c6a9qaq6dOlSe3P9+vX25vvvv29vFhYW2puqsSNja2tr7c3y8nJ7M3JE782bN+1N1dihuqWlpfZm5Gd7/Pjx9mbkeGPV2PG9+/fvtzePHz9ub7a2ttqbz40nBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYBwEK9pdna2vTlx4kR7M3osbOSY2ZUrV9qb0YN9I54+fdre3L17t70ZOZr2n//8p73Z3Nxsb6qqjhw50t6M/GxHjBxVnJ+fH3qtc+fOtTeLi4vtzcgBwi+BJwUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGA2NcH8SaTSXszciRrYWGhvbl48WJ7UzV2AG3kwNjIYcDV1dX2pqrq1q1b7c2vv/7a3jx48KC9WVtba28+fPjQ3lRVHT9+vL0Z+Y6PfB+Wlpbam9GDeCMHJk+dOtXezM3NtTdfAk8KAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAMS+vpJ64EC/iSOXKkeuTl6+fLm9qaq6cOFCe3Ps2LH2ZmNjo725f/9+e1M1dvF05LLqyspKe/P27dv2ZjqdtjdVVR8/fmxv1tfX25tXr161N5ubm+3NyO9S1diF3qNHj7Y3hw4dam++BJ4UAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAGJfH8SbmZlpb06ePNneLC0ttTcXL15sb6qqFhYW2pvd3d32Znl5ub25fft2e1NVdefOnfbm8ePH7c2bN2/am5EjdSOHGKuq5ubm2pudnZ092Yx8DiPfu6qxg4Ijn/nBg/1/HieTSXtTNX4k8d/gSQGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAg9vVBvJGDVyMH50YO4n3zzTftTVXV0aNH25vnz5+3N3/99Vd7c+/evfamqmplZaW9GTlu9+HDh/Zm5JDZ6NG0kQOOhw8fbm+OHDnS3oz8Lo0c3quqev/+/Z5sPqcjdXvJkwIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBA7OuDeCPHwhYXF9ubkeN2J06caG+qqnZ3d9ubvTqI9+TJk/amqur169ftzchxu5EDbQcO9P+7anZ2tr2pqpqfn29vRr6vp0+fbm/m5ubam5EjdVVjxw43Njbam5Hv0JfAkwIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBA7OuDeIcOHWpvTp061d6cPHmyvRk5MFY1dmRs5CDes2fP2puRw3ZVVdvb2+3NyGHAkeN2I0cVR74PVVXnz59vby5dutTenDt3rr0Z+V1aX19vb6qq1tbW2puXL1+2N+/evWtvvgSeFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFACIfX0ldeTC5dGjR9ubkYunIxc7q8aupG5ubrY3W1tb7c3Ozk57U1U1mUzam9nZ2fZm5NLnyMXTkculVVU//PBDe3Pt2rX2ZnFxsb0ZuUo7cp23qmplZaW9WV1dbW9GvuPT6bS9+dx4UgAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFACIfX0Qb+To3MjBq708kjUzM9PejByCO378eHszPz/f3lSNfX4jP9uR9/ftt9+2Nzdu3Ghvqqp+/vnn9ua7775rb0YOOD59+rS9efToUXtTVfX48eP25u+//25vRo5Lfgk8KQAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgDEvj6It7u72968ffu2vdna2mpvRt5b1dihupGjbtevX29vJpNJe1NVtbGx0d6MHPk7e/ZsezNycO7q1avtTVXV0tJSezPyOayurrY3Dx482JNN1dhBvPX19fZme3u7vfkSeFIAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQAiH19EO/9+/ftzfPnz9ubtbW19mbkCFxV1fnz59ubmzdvtjfz8/PtzcgRvaq9O4h3+vTp9mbkiN7IZ1dVNZ1O25uVlZX25u7du+3N7du325t79+61N1VVz549a282Nzfbm9GjlP/rPCkAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAxL4+iPf27dv25smTJ+3NyOGvc+fOtTdVY0fdlpaW2ptvv/22vdna2mpvRnc7OzvtzczMTHszcqTu5cuX7U1V1aNHj9qbW7dutTe///57e/PHH3+0N8vLy+1NVdX6+np78/Hjx/Zm5Gf7JfCkAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAEDs6yup7969a29WVlbam99++629OXToUHszand3t725cOFCe3Py5Mn2pqrqxIkT7c3Iz/bFixftzePHj9ubu3fvtjdVYxdP79y50948fPiwvXn27Fl7s7Gx0d5UVW1vb7c3I9/x/cqTAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAEBMptPp9JP+4GTyb7+XPTfydxo5VDdy0G3k4FxV1bVr19qbGzdutDdXrlxpb86cOdPeVFXNzMy0N+vr6+3NkydP2ps///xzTzZVY8f31tbW2pvXr1+3N+/fv29vdnZ22puqqk/8J4v/x6d8dp4UAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAGJfH8TbKwcO9Ns7Ozs79Fpzc3PtzbFjx9qbo0ePtjcj761q7PMbOba2tbXV3rx9+3ZPXqdq7Ojc9vZ2e7O7u9veOFL3v8FBPABaRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIB/EA9gkH8QBoEQUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQAiIOf+gen0+m/+T4A+Ax4UgAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACD+DwqhnJTawz1PAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mu, sigma, pi = fit_generative_model(train_data, train_labels)\n",
    "displaychar(mu[0])\n",
    "displaychar(mu[1])\n",
    "displaychar(mu[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Make predictions on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how many errors your model makes on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your model makes 2190 errors out of 10000\n",
      "This is 21.9% error rate\n"
     ]
    }
   ],
   "source": [
    "# Compute log Pr(label|image) for each [test image,label] pair.\n",
    "k = 10\n",
    "score = np.zeros((len(test_labels),k))\n",
    "for label in range(0,k):\n",
    "    rv = multivariate_normal(mean=mu[label], cov=sigma[label])\n",
    "    for i in range(0,len(test_labels)):\n",
    "       score[i,label] = np.log(pi[label]) + rv.logpdf(test_data[i,:])\n",
    "predictions = np.argmax(score, axis=1)\n",
    "# Finally, tally up score\n",
    "errors = np.sum(predictions != test_labels)\n",
    "print(\"Your model makes \" + str(errors) + \" errors out of 10000\")\n",
    "print(\"This is \" + str(errors/100) + \"% error rate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your model makes 2190 errors out of 10000\n",
      "This is 21.90% error rate\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Compute log-likelihoods\n",
    "k = 10\n",
    "score = np.zeros((len(test_labels), k))\n",
    "\n",
    "for label in range(0, k):\n",
    "    rv = multivariate_normal(mean=mu[label], cov=sigma[label])\n",
    "    for i in range(0, len(test_labels)):\n",
    "        score[i, label] = np.log(pi[label]) + rv.logpdf(test_data[i, :])\n",
    "\n",
    "# Step 2: Assign labels\n",
    "predictions = np.argmax(score, axis=1)\n",
    "\n",
    "# Step 3: Evaluate performance\n",
    "errors = np.sum(predictions != test_labels)\n",
    "error_rate = errors / len(test_labels) * 100\n",
    "print(\"Your model makes {} errors out of {}\".format(errors, len(test_labels)))\n",
    "print(\"This is {:.2f}% error rate\".format(error_rate))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 2 1 ... 9 5 6]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Quick exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*You will need to answer variants of these questions as part of this week's assignment*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"magenta\">Exercise 1:</font> What happens if you do not regularize the covariance matrices?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**If you do not regularize the covariance matrices in a Gaussian generative model, several issues can arise:**\n",
    "\n",
    "1. **Singularity**: The empirical covariance matrices computed from the training data may be singular or nearly singular, especially if the number of training samples is small relative to the number of features. This singularity can lead to numerical instability and difficulties in computing the inverse of the covariance matrix.\n",
    "\n",
    "2. **Overfitting**: Without regularization, the covariance matrices can become too sensitive to noise and variability in the training data. This can lead to overfitting, where the model captures not only the underlying patterns in the data but also the noise, resulting in poor generalization performance on unseen data.\n",
    "\n",
    "3. **Ill-Conditioning**: Covariance matrices estimated from limited data can be ill-conditioned, meaning that they have very small eigenvalues or a large condition number. This ill-conditioning can amplify the effects of noise and make the model less robust.\n",
    "\n",
    "4. **Degenerate Solutions**: In extreme cases, without regularization, the covariance matrices may become degenerate, meaning that they have zero determinants. This implies that the data points in certain dimensions are perfectly correlated, leading to unrealistic and unreliable models.\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"magenta\">Exercise 2:</font> What happens if you set the value of `c` too high, for instance to one billion? Do you understand why this happens?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Consequences of setting `c` too high in Gaussian generative model regularization:**\n",
    "\n",
    "1. **Over-regularization**: Excessive regularization dominates, ignoring important information in the covariance matrices.\n",
    "\n",
    "2. **Loss of Information**: Overly smoothed covariance matrices lead to loss of data complexity, resulting in suboptimal performance.\n",
    "\n",
    "3. **Underfitting**: Simplistic model fails to capture underlying data patterns, resulting in poor generalization.\n",
    "\n",
    "4. **Decreased Discriminative Power**: Reduced ability to distinguish between classes, leading to higher classification errors.\n",
    "\n",
    "**Summary**: Excessive `c` results in underfitting, loss of information, and reduced model discriminative power. Optimal `c` balancing regularization and data complexity is crucial for model performance.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"magenta\">Exercise 3:</font> What value of c did you end up using? How many errors did your model make on the training set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I ended up using a regularization parameter `c` of `1e-2` (0.01) in the Gaussian generative model. \n",
    "\n",
    "The error rates of the model on the test data were as follows:\n",
    "\n",
    "- **Number of errors**: 2190 errors out of 10000 predictions.\n",
    "- **Error rate**: 21.90%\n",
    "\n",
    "This error rate indicates that approximately 21.90% of the predictions made by the model on the test data were incorrect.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"magenta\">If you have the time</font>: We have talked about using the same regularization constant `c` for all ten classes. What about using a different value of `c` for each class? How would you go about choosing these? Can you get better performance in this way?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
